Top 10 List of Week 00

1. Virtual Memory Concept in Hardware and Software.
    - Virtual memory is a memory management technique where secondary memory can be used as if it were a part of the main memory. Virtual memory is a very common technique used in the operating systems (OS) of computers.
    - Virtual memory uses hardware and software to allow a computer to compensate for physical memory shortages, by temporarily transferring data from random access memory (RAM) to disk storage. In essence, virtual memory allows a computer to treat secondary memory as though it were the main memory.

2. Virtual File System
    - The Linux kernel requires that for an entity to be a filesystem, it must also implement the open(), read(), and write() methods on persistent objects that have names associated with them. From the point of view of object-oriented programming, the kernel treats the generic filesystem as an abstract interface, and these big-three functions are "virtual," with no default definition. Accordingly, the kernel's default filesystem implementation is called a virtual filesystem (VFS).

3. Free Software Definition
    - The freedom to run the program as you wish, for any purpose (freedom 0).
    - The freedom to study how the program works, and change it so it does your computing as you wish (freedom 1). Access to the source code is a precondition for this.
    - The freedom to redistribute copies so you can help your neighbor (freedom 2).
    - The freedom to distribute copies of your modified versions to others (freedom 3). By doing this you can give the whole community a chance to benefit from your changes. Access to the source code is a precondition for this.

4. Virtual Machine
    - In computing, a virtual machine (VM) is an emulation of a computer system. Virtual machines are based on computer architectures and provide functionality of a physical computer. Their implementations may involve specialized hardware, software, or a combination.

5. Cloud Computing
    - Cloud computing is the on-demand availability of computer system resources, especially data storage (cloud storage) and computing power, without direct active management by the user. The term is generally used to describe data centers available to many users over the Internet.[1] Large clouds, predominant today, often have functions distributed over multiple locations from central servers. If the connection to the user is relatively close, it may be designated an edge server.
    
6. Scripting Commmand
    - The script command is a Unix utility that records a terminal session. It dates back to the 1979 3.0 BSD. The session is captured in file name typescript by default; to specify a different filename follow the script command with a space and the filename as such: script recorded_session.
    
7. Regex
    - A regular expression (shortened as regex or regexp; also referred to as rational expression) is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for "find" or "find and replace" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.
    
8. User Access
    - Access control is a security technique that regulates who or what can view or use resources in a computing environment. ... Physical access control limits access to campuses, buildings, rooms and physical IT assets. Logical access control limits connections to computer networks, system files and data.
    
9. SSH
    - Secure Shell (SSH) is a cryptographic network protocol for operating network services securely over an unsecured network. Typical applications include remote command-line, login, and remote command execution, but any network service can be secured with SSH.
    
10. Unix Environment
    - UNIX is an operating system consisting of three important features; a kernel, the shell and a file system. As its name implies, the kernel is at the core of each UNIX system and is loaded in whenever the system is started up - referred to as a boot of the system. It manages the entire resources of the system, presenting them to you and every other user as a coherent system. You do not need to know anything about the kernel in order to use a UNIX system. Amongst the functions performed by the kernel are:
      - managing the machine's memory and allocating it to each process.
      - scheduling the work done by the CPU so that the work of each user is carried out as efficiently as is possible.
      - organizing the transfer of data from one part of the machine to another.
      - accepting instructions from the shell and carrying them out.
      - enforcing the access permissions that are in force on the file system.
