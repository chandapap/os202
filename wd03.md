Top 10 List of Week 03

1. GnuPG
    - GnuPG is a complete and free implementation of the OpenPGP standard as defined by RFC4880 (also known as PGP). GnuPG allows you to encrypt and sign your data and communications; 
      it features a versatile key management system, along with access modules for all kinds of public key directories. GnuPG, also known as GPG, is a command line tool with features for easy integration with other applications. 
      A wealth of frontend applications and libraries are available. GnuPG also provides support for S/MIME and Secure Shell (ssh).
      Since its introduction in 1997, GnuPG is Free Software (meaning that it respects your freedom). It can be freely used, modified and distributed under the terms of the GNU General Public License .
      The current version of GnuPG is 2.2.23. See the download page for other maintained versions.
      Gpg4win is a Windows version of GnuPG featuring a context menu tool, a crypto manager, and an Outlook plugin to send and receive standard PGP/MIME mails. The current version of Gpg4win is 3.1.13.

2. File Concept
    - Computers can store information on various storage media, such as magnetic disks, magnetic tapes, and optical disks. 
      So that the computer system will be convenient to use, the operating system provides a uniform logical view of information storage. 
      The operating system abstracts from the physical properties of its storage devices to define a logical storage unit, the file. Files are mapped by the operating system onto physical devices. 
      These storage devices are usually nonvolatile, so the contents are persistent through power failures and system reboots.
      A file is a named collection of related information that is recorded on secondary storage. From a user's perspective, a tile is the smallest allotment of logical secondary storage; 
      that is, data cannot be written to secondary storage unless they are within a file. Commonly, files represent programs (both source and object forms) and data. Data files may be numeric, alphabetic, alphanumeric, or binary.
      Files may be free form, such as text files, or may be formatted rigidly. In general, a file is a sequence of bits, bytes, lines, or records, the meaning of which is defined by the file's creator and user. 
      The concept of a file is thus extremely general. The information in a file is defined by its creator. Many different types of information may be stored in a file—source programs, object programs, executable programs, numeric data, text, payroll records, graphic images, sound recordings, and so on. A file has a certain defined structure, which depends on its type. A text file is a sequence of characters organized into lines (and possibly pages). A source file is a sequence of subroutines and functions, each of which is further organized as declarations followed by executable statements. An object file is a sequence of bytes organized into blocks understandable by the system's linker. An executable file is a series of code sections that the loader can bring into memory and execute.

3. Access Method
    - Most of the operating systems access the file sequentially. In other words, we can say that most of the files need to be accessed sequentially by the operating system.
      In sequential access, the OS read the file word by word. A pointer is maintained which initially points to the base address of the file. If the user wants to read first word of the file then the pointer provides that word to the user and increases its value by 1 word. This process continues till the end of the file.
      Modern word systems do provide the concept of direct access and indexed access but the most used method is sequential access due to the fact that most of the files such as text files, audio files, video files, etc need to be sequentially accessed.
      1. Direct Access
        The Direct Access is mostly required in the case of database systems. In most of the cases, we need filtered information from the database. The sequential access can be very slow and inefficient in such cases.
        Suppose every block of the storage stores 4 records and we know that the record we needed is stored in 10th block. In that case, the sequential access will not be implemented because it will traverse all the blocks in order to access the needed record.
        Direct access will give the required result despite of the fact that the operating system has to perform some complex tasks such as determining the desired block number. However, that is generally implemented in database applications.
      2. Sequential Access
        It is the simplest access method. Information in the file is processed in order, one record after the other. This mode of access is by far the most common; for example, editor and compiler usually access the file in this fashion. 
        Read and write make up the bulk of the operation on a file. A read operation -read next- read the next position of the file and automatically advance a file pointer, which keeps track I/O location. Similarly, for the writewrite next append to the end of the file and advance to the newly written material. 
      3. Index sequential method
        It is the other method of accessing a file which is built on the top of the direct access method. These methods construct an index for the file. The index, like an index in the back of a book, contains the pointer to the various blocks. To find a record in the file, we first search the index and then by the help of pointer we access the file directly. 
    
4. Disk Defragmentation
    - Defragmentation, also known as “defrag” or “defragging” is the process of reorganizing the data stored on the hard drive so that related pieces of data are put back together, all lined up in a continuous fashion.  You could say that defragmentation is like cleaning house for your server or PC, it picks up all of the pieces of data that are spread across your hard drive and puts them back together again.
      Why is defragmentation important? Because every computer suffers from the constant growth of fragmentation and if you don’t “clean house”, your servers and PCs suffer.
      How Fragmentation Occurs
        Disk fragmentation occurs when a file is broken up into pieces to fit on the disk. Because files are constantly being written, deleted and resized, fragmentation is a natural occurrence. When a file is spread out over several locations, it takes longer to read and write. But the effects of fragmentation are far more widespread.
      Effects of Fragmentation on Computer Performance
        Many users blame computer performance problems on the operating system or simply think their computer is “old”, when disk fragmentation is most often the real culprit. The weakest link in computer performance is the disk. It is at least 100,000 times slower than RAM and over 2 million times slower than the CPU. In terms of computer performance, the disk is the primary bottleneck. File fragmentation directly affects the access and write speed of that disk, steadily corrupting computer performance to unviable levels. Because all computers suffer from fragmentation, this is a critical issue to resolve.

5. Partition
    - When referring to a computer hard drive, a disk partition or partition is a section of the hard drive that is separated from other segments. Partitions enable users to divide a physical disk into logical sections. For example, allowing multiple operating systems to run on the same device.
      With older file allocation tables, such as FAT 16, creating smaller partitions allows a computer hard drive to run more efficiently and save more disk space. However, with new file allocation tables, such as FAT32, this is no longer the case.
      Types of partitions
      There are also several partition types. Below is a listing of some of these partitions with a brief description. Some of these partitions may not be available in your partition utility.
        Partition	                    Description
        AIX partition (boot)	        A partition used with the AIX operating system.
        Boot partition	              As defined by Microsoft, a boot partition is a partition that contains the files required for a system startup. Also see: System partition
        BSD/OS partition (OpenBSD)	  A partition used with the BSD operating system.
        DOS partition (12/16-bit)	A partition used with older versions of MS-DOS.
        DOS extended partition	      A partition that is extended from one or more of the original MS-DOS partitions.
        DRDOS (hHidden)	              A partition used with the DR. DOS operating system.
        Extended partition	          A partition that is extended from one or more of the primary partitions.
        Hibernation partition	        A partition used with older hibernation programs.
        HPFS partition (OS/2 IFS)	    An HPFS partition used with IBM OS/2 and Microsoft NT 3.x
        Linux 	                      A partition used with various variants of the Linux operating systems.
        MINIX	                        A partition used with the MINIX operating system.
        NON-DOS                       A NON-DOS partition indicates a partition that is not native to the Microsoft operating system. For example, this could be a Linux partition.
        NEC DOS	                      A partition used with the old NEC DOS variant.
        NEXTSTEP	                    A partition used with the NeXTSTEP operating system.
        Novell NetWare	              A partition used with the Novell NetWare operating system.
        NTFS	                        A partition used with Microsoft Windows NT 4.x, Windows 2000 and Windows XP.
        Partition Magic (PowerQuest)	A partition created using the Partition Magic utility by PowerQuest.
        PC-ARMOUR	                    A partition created by the PC ARMOUR security utility. When created this partition is commonly protected by a password.
        Primary	                      In a Microsoft operating system, the Primary Partition refers to the main or first partition used for the Microsoft operating system.
        Solaris X86	                  A partition used with the Sun Solaris X86 platform operating system.
        System partition	            As defined by Microsoft, a system partition is a partition that contains the system32 directory. Also see: boot partition.
        Tandy DOS	                    A partition used with the old Tandy DOS variant.
        Unix System V (SCO, IRIX, ISC, Unix, UnixWare, etc...)	A partition used with various Unix operating systems.
        VMware (VMware Swap)	        A partition used by VMware.
        XENIX (XENIX /usr)	          A partition used with the Xenix operating system.

6. Virtual FS
    - The Virtual File System (also known as the Virtual Filesystem Switch) is the software layer in the kernel that provides the filesystem interface to userspace programs. It also provides an abstraction within the kernel which allows different filesystem implementations to coexist.
      VFS system calls open(2), stat(2), read(2), write(2), chmod(2) and so on are called from a process context. Filesystem locking is described in the document Documentation/filesystems/locking.rst.
      Directory Entry Cache (dcache)
        The VFS implements the open(2), stat(2), chmod(2), and similar system calls. The pathname argument that is passed to them is used by the VFS to search through the directory entry cache (also known as the dentry cache or dcache). This provides a very fast look-up mechanism to translate a pathname (filename) into a specific dentry. Dentries live in RAM and are never saved to disc: they exist only for performance.
        The dentry cache is meant to be a view into your entire filespace. As most computers cannot fit all dentries in the RAM at the same time, some bits of the cache are missing. In order to resolve your pathname into a dentry, the VFS may have to resort to creating dentries along the way, and then loading the inode. This is done by looking up the inode.
      The Inode Object
        An individual dentry usually has a pointer to an inode. Inodes are filesystem objects such as regular files, directories, FIFOs and other beasts. They live either on the disc (for block device filesystems) or in the memory (for pseudo filesystems). Inodes that live on the disc are copied into the memory when required and changes to the inode are written back to disc. A single inode can be pointed to by multiple dentries (hard links, for example, do this).
        To look up an inode requires that the VFS calls the lookup() method of the parent directory inode. This method is installed by the specific filesystem implementation that the inode lives in. Once the VFS has the required dentry (and hence the inode), we can do all those boring things like open(2) the file, or stat(2) it to peek at the inode data. The stat(2) operation is fairly simple: once the VFS has the dentry, it peeks at the inode data and passes some of it back to userspace.
      The File Object
        Opening a file requires another operation: allocation of a file structure (this is the kernel-side implementation of file descriptors). The freshly allocated file structure is initialized with a pointer to the dentry and a set of file operation member functions. These are taken from the inode data. The open() file method is then called so the specific filesystem implementation can do its work. You can see that this is another switch performed by the VFS. The file structure is placed into the file descriptor table for the process.
        Reading, writing and closing files (and other assorted VFS operations) is done by using the userspace file descriptor to grab the appropriate file structure, and then calling the required file structure method to do whatever is required. For as long as the file is open, it keeps the dentry in use, which in turn means that the VFS inode is still in use.

7. Directory Structure
    - The directory structure is the organization of files into a hierarchy of folders. It should be stable and scalable; it should not fundamentally change, only be added to. Computers have used the folder metaphor for decades as a way to help users keep track of where something can be found.
      Folders are very limited as an organizational structure, however. There must be one top-level organizational construct, which can only be subdivided in a limited way before the system becomes too cumbersome and breaks down. Which is most important to divide by: date, client, project, subject matter, rating, or usage?
      Furthermore, information that is dependent on folder structure is very fragile. If you remove an image from a folder that designates what that image is, that content information can be lost; however, folders provide an ideal tool for managing the data itself. We suggest you should use folders principally for storage, rather than for organization.
      By storage, we mean containing the images, putting them away, moving them around, and other handling issues, distinct from the organization of the images that is best accomplished by using metadata.
      In the physical world, storage and organizational structure are often inseparable. In the digital world, we are not so constrained. We’ll see how you can use folders in a simple, straightforward way to stack files up so that you can back them up, validate them, and restore them in the event of a problem. 
      This does not mean that folder naming is irrelevant as a content-organizing tool; it means that content organizing is a secondary job.

8. Access Control Lists
    - Access control list (ACL) provides an additional, more flexible permission mechanism for file systems. It is designed to assist with UNIX file permissions. ACL allows you to give permissions for any user or group to any disc resource.
      Use of ACL :
        Think of a scenario in which a particular user is not a member of group created by you but still you want to give some read or write access, how can you do it without making user a member of group, here comes in picture Access Control Lists, ACL helps us to do this trick.
        Basically, ACLs are used to make a flexible permission mechanism in Linux.
        From Linux man pages, ACLs are used to define more fine-grained discretionary access rights for files and directories.
        setfacl and getfacl are used for setting up ACL and showing ACL respectively.

9. Free Space Management OS
    - The system keeps tracks of the free disk blocks for allocating space to files when they are created. Also, to reuse the space released from deleting the files, free space management becomes crucial. The system maintains a free space list which keeps track of the disk blocks that are not allocated to some file or directory. The free space list can be implemented mainly as:
      Bitmap or Bit vector –
        A Bitmap or Bit Vector is series or collection of bits where each bit corresponds to a disk block. The bit can take two values: 0 and 1: 0 indicates that the block is allocated and 1 indicates a free block.
        The given instance of disk blocks on the disk in Figure 1 (where green blocks are allocated) can be represented by a bitmap of 16 bits as: 0000111000000110.
      Simple to understand.
        Finding the first free block is efficient. It requires scanning the words (a group of 8 bits) in a bitmap for a non-zero word. (A 0-valued word has all bits 0). The first free block is then found by scanning for the first 1 bit in the non-zero word.
        The block number can be calculated as:
        (number of bits per word) *(number of 0-values words) + offset of bit first bit 1 in the non-zero word .

10. File Locking
    - File locking is a data management feature that restricts other users from changing a specific file. This allows only one user or process access to this file at any given time. This is to prevent the problem of interceding updates on the same files.
      For example, if process A and process B open the same file, process A then changes the file and saves it. Process B, which still has the original state file, makes some changes then saves it, rendering the changes made by process A lost.
      The file locking mechanism was introduced by IBM in 1963 in mainframe computers that used the OS/360. At the time, it was called "exclusive control." This is a first-come, first-served method for file management in multiuser systems. The first process or user to access the file locks out other users from being able to access it. When the file has been updated and control has been relinquished, it becomes unlocked and available for others to access. Modern implementation of this method allows for multiple users to access the file but only the first one to access it may modify it. Some applications allow interceding updates with all the changes selectively merged later on, whether manually or automatically.
